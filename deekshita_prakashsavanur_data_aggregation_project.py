# -*- coding: utf-8 -*-
"""Deekshita_PrakashSavanur_data_aggregation_project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FaO_eqWXAeiuckGtBqqTb8bvaZKrlVGn
"""

# Importing libraries
import requests
import re
import pandas as pd
import nltk

from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

nltk.download('punkt')
nltk.download('stopwords')

# Assumption : Using provided City Lat Longs file in resource section of project as input to my python program
# Read input csv file to get value of Latitude, Longitude, City, State
city_lat_longs_input_df= pd.read_csv('City_Lat_Longs.csv')
lat_list = city_lat_longs_input_df['Latitude']
lon_list = city_lat_longs_input_df['Longitude']
city_list = city_lat_longs_input_df['City']
state_list = city_lat_longs_input_df['State']

# Openweathermap API details
api_key = 'e1d8dcfba9ad1673d648d9255d7c5cf3'
base_url = 'https://api.openweathermap.org/data/3.0/onecall/overview'

# Variable declaration
weather_overviews_all_location = []
temperatures = []
feels_like_temperatures = []
uv_indices = []

def text_preprocessing(weather_overview):
  tokenized_weather_overview = word_tokenize(weather_overview)

  # Remove stopwords using NLTK
  new_filtered_weather_overview = [
      word for word in tokenized_weather_overview if word.lower() not in stopwords.words('english')]

  new_clean_weather_overview = ' '.join(new_filtered_weather_overview)
  return new_clean_weather_overview

def makeOpenWeatherMap_api_call():
  for lat, lon in zip(lat_list,lon_list):

      request_url = f"{base_url}?lat={lat}&lon={lon}&appid={api_key}&units=imperial"
      # Make API to get Weather overivew details in imperial units
      response = requests.get(request_url)

      if response.status_code == 200:
          weather_data = response.json()
          if 'tz' in weather_data:
            weather_data.pop('tz') # Remove the “tz” key, value pair
          weather_overviews_all_location.append(text_preprocessing(weather_data.get("weather_overview"))) # Text pre-formatting by removing stopwords
      else:
          print(f"Failed to get weather data. HTTP Status code: {response.status_code}")

def extract_columns_data():
  # Define regex patterns for the current temperature, feels-like temperature, and UV index
  temperature_pattern = re.compile(r'temperature (\d+)')
  feels_like_pattern = re.compile(r'\b(feels? like|feels?-like|feels?-like temperature|feels? like temperature|real feel)s?\s+(\d+)')
  uv_index_pattern = re.compile(r'UV index (\d+)')

  # Extract data using regex patterns
  for overview in weather_overviews_all_location:
      temperature_match = temperature_pattern.search(overview)
      feels_like_match = feels_like_pattern.search(overview)
      uv_index_match = uv_index_pattern.search(overview)

      temperatures.append(temperature_match.group(1) if temperature_match else None)
      feels_like_temperatures.append(feels_like_match.group(2) if feels_like_match else None)
      uv_indices.append(int(uv_index_match.group(1)) if uv_index_match else None)

def filter_df_data_and_export():
  # Create a DataFrame with the extracted data
  df = pd.DataFrame({
      'City' : city_list,
      'State' : state_list,
      'Current Temperature (F)': temperatures,
      'Feels-like Temperature': feels_like_temperatures,
      'UV Index': uv_indices
  })
  print('='*50)
  print(df) # Data with Current Temperatures
  print('='*50)

  # Convert Fahrenheit to Celsius for current temperatures
  df["Current Temperature (C)"]= ((df["Current Temperature (F)"].astype(str).astype(int)-32)*5)/9

  # Filter DataFrame where the daily temperature is below 78 degrees
  result_df = df[df['Current Temperature (F)'].astype(str).astype(int) < 78]
  print(result_df)

  # Export to Excel Spreadsheet file
  result_df.to_excel("Output_City_Lat_Longs.xlsx")

makeOpenWeatherMap_api_call()
extract_columns_data()
filter_df_data_and_export()

